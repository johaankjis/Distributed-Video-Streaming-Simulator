# Distributed Video Streaming Simulator

A comprehensive distributed video streaming system simulator built with Next.js frontend, Python gRPC backend, and Kubernetes orchestration. This project demonstrates a production-grade architecture for video content delivery with real-time monitoring, load balancing, and observability.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Next.js](https://img.shields.io/badge/Next.js-15.2.4-black)
![Python](https://img.shields.io/badge/Python-3.11-blue)
![gRPC](https://img.shields.io/badge/gRPC-1.60.0-green)
![Kubernetes](https://img.shields.io/badge/Kubernetes-Ready-326CE5)

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Features](#features)
- [Technology Stack](#technology-stack)
- [Prerequisites](#prerequisites)
- [Getting Started](#getting-started)
  - [Frontend Setup](#frontend-setup)
  - [Backend Setup](#backend-setup)
  - [Kubernetes Deployment](#kubernetes-deployment)
- [Monitoring & Observability](#monitoring--observability)
- [Project Structure](#project-structure)
- [gRPC API Documentation](#grpc-api-documentation)
- [Configuration](#configuration)
- [Development](#development)
- [Contributing](#contributing)
- [License](#license)

## ğŸ¯ Overview

This project simulates a distributed video streaming infrastructure that can handle thousands of concurrent video streams. It includes:

- **Frontend Dashboard**: A modern Next.js web application with real-time metrics visualization
- **gRPC Streaming Servers**: Python-based video streaming servers with adaptive bitrate support
- **Load Simulator**: Automated load testing client that simulates concurrent user behavior
- **Monitoring Stack**: Prometheus for metrics collection and Grafana for visualization
- **Kubernetes Orchestration**: Full containerization and orchestration with auto-scaling capabilities

## ğŸ—ï¸ Architecture

The system follows a microservices architecture with the following components:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Next.js Web UI â”‚
â”‚  (Dashboard)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Kubernetes Cluster                 â”‚
â”‚                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  gRPC Video Servers (5 replicas)     â”‚ â”‚
â”‚  â”‚  - Adaptive bitrate streaming        â”‚ â”‚
â”‚  â”‚  - Health monitoring                 â”‚ â”‚
â”‚  â”‚  - Prometheus metrics export         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚             â”‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Load Simulator Clients              â”‚ â”‚
â”‚  â”‚  - Concurrent stream requests        â”‚ â”‚
â”‚  â”‚  - Quality adaptation                â”‚ â”‚
â”‚  â”‚  - Load balancing                    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚             â”‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Prometheus (Metrics Collection)     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚             â”‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Grafana (Visualization)             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Features

### Frontend Dashboard
- ğŸ“Š Real-time metrics visualization with interactive charts
- ğŸ¨ Modern UI built with shadcn/ui and Tailwind CSS
- ğŸ“ˆ Stream quality distribution analytics
- ğŸ”„ Live data updates and monitoring
- ğŸ¯ Responsive design for desktop and mobile

### Video Streaming Backend
- ğŸ¬ gRPC-based streaming protocol for efficient data transfer
- ğŸšï¸ Adaptive bitrate streaming (Low, Medium, High quality)
- âš¡ Concurrent stream handling with thread pool
- ğŸ“Š Prometheus metrics export for observability
- ğŸ”„ Automatic error recovery and retry logic
- ğŸ’¾ Configurable chunk sizes and streaming parameters

### Load Simulation
- ğŸ‘¥ Simulates 100+ concurrent clients
- ğŸ² Random quality selection and server distribution
- ğŸ“Š Client-side metrics collection
- ğŸ”„ Configurable test scenarios
- â±ï¸ Realistic network delay simulation

### Monitoring & Observability
- ğŸ“ˆ Prometheus for metrics aggregation
- ğŸ“Š Grafana dashboards for visualization
- ğŸ” Custom metrics for stream quality, latency, and errors
- ğŸš¨ Health checks and liveness probes
- ğŸ“‰ Historical data analysis

## ğŸ› ï¸ Technology Stack

### Frontend
- **Framework**: Next.js 15.2.4 with React 19
- **Language**: TypeScript 5
- **Styling**: Tailwind CSS 4.1.9
- **UI Components**: Radix UI primitives, shadcn/ui
- **Charts**: Recharts for data visualization
- **Icons**: Lucide React
- **Analytics**: Vercel Analytics

### Backend
- **Language**: Python 3.11
- **RPC Framework**: gRPC 1.60.0
- **Metrics**: Prometheus Client 0.19.0
- **Protocol Buffers**: protobuf 3

### Infrastructure
- **Containerization**: Docker
- **Orchestration**: Kubernetes
- **Monitoring**: Prometheus + Grafana
- **Service Mesh**: Built-in load balancing

## ğŸ“¦ Prerequisites

Before you begin, ensure you have the following installed:

- **Node.js** 18+ and pnpm
- **Python** 3.11+
- **Docker** 20.10+
- **Kubernetes** (minikube, kind, or cloud provider)
- **kubectl** configured and connected to your cluster
- **Git** for version control

## ğŸš€ Getting Started

### Frontend Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/johaankjis/Distributed-Video-Streaming-Simulator.git
   cd Distributed-Video-Streaming-Simulator
   ```

2. **Install dependencies**
   ```bash
   pnpm install
   ```

3. **Run the development server**
   ```bash
   pnpm dev
   ```

4. **Build for production**
   ```bash
   pnpm build
   pnpm start
   ```

The frontend will be available at `http://localhost:3000`

### Backend Setup

#### Local Development (Python)

1. **Navigate to server directory**
   ```bash
   cd server
   ```

2. **Install Python dependencies**
   ```bash
   pip install grpcio==1.60.0 grpcio-tools==1.60.0 prometheus-client==0.19.0
   ```

3. **Generate gRPC code from proto file**
   ```bash
   python -m grpc_tools.protoc \
     -I. \
     --python_out=. \
     --grpc_python_out=. \
     video_streaming.proto
   ```

4. **Run the video server**
   ```bash
   python video_server.py
   ```

The gRPC server will start on port `50051` and Prometheus metrics will be available at `http://localhost:8000/metrics`

#### Client Load Simulator

1. **Navigate to client directory**
   ```bash
   cd client
   ```

2. **Install dependencies**
   ```bash
   pip install grpcio==1.60.0 grpcio-tools==1.60.0 prometheus-client==0.19.0
   ```

3. **Generate gRPC code**
   ```bash
   python -m grpc_tools.protoc \
     -I../server \
     --python_out=. \
     --grpc_python_out=. \
     ../server/video_streaming.proto
   ```

4. **Run the load simulator**
   ```bash
   # Connect to local server
   SERVER_ADDRESSES=localhost:50051 NUM_CLIENTS=10 python load_simulator.py
   ```

Client metrics will be available at `http://localhost:8001/metrics`

### Kubernetes Deployment

#### Quick Start with Script

```bash
# Make the script executable
chmod +x scripts/build-and-deploy.sh

# Build and deploy
./scripts/build-and-deploy.sh
```

#### Manual Deployment

1. **Build Docker images**
   ```bash
   # Build server image
   docker build -t video-streaming-server:latest -f server/Dockerfile server/

   # Build client image
   docker build -t video-streaming-client:latest -f client/Dockerfile client/
   ```

2. **Deploy to Kubernetes**
   ```bash
   # Deploy video servers (5 replicas)
   kubectl apply -f kubernetes/video-server-deployment.yaml

   # Deploy load simulator clients
   kubectl apply -f kubernetes/client-deployment.yaml

   # Deploy Prometheus
   kubectl apply -f kubernetes/prometheus-config.yaml

   # Deploy Grafana
   kubectl apply -f kubernetes/grafana-deployment.yaml
   ```

3. **Verify deployment**
   ```bash
   kubectl get pods
   kubectl get services
   ```

4. **Access services**
   - Prometheus: `http://localhost:30090`
   - Grafana: `http://localhost:30030` (credentials: admin/admin)

## ğŸ“Š Monitoring & Observability

### Prometheus Metrics

The system exports the following metrics:

#### Server Metrics
- `video_streams_total`: Total number of video streams by quality and node
- `video_chunks_sent_total`: Total chunks sent by node
- `stream_chunk_latency_seconds`: Histogram of chunk delivery latency
- `active_connections`: Current number of active streaming connections
- `chunk_errors_total`: Total chunk delivery errors

#### Client Metrics
- `client_streams_total`: Total streams initiated by quality
- `client_chunks_received_total`: Total chunks received
- `client_stream_latency_seconds`: Client-side stream latency histogram
- `client_errors_total`: Total client errors by type
- `active_clients`: Number of active client connections

### Grafana Dashboards

Access Grafana at `http://localhost:30030` and import the pre-configured dashboard:

```bash
# Dashboard is located at
grafana/dashboard.json
```

The dashboard includes:
- Real-time stream metrics
- Quality distribution pie charts
- Latency histograms
- Error rates and trends
- Server health status
- Active connections monitoring

### Health Checks

```bash
# Check server health via gRPC
grpcurl -plaintext localhost:50051 videostreaming.VideoStreamingService/GetServerHealth

# Check metrics endpoint
curl http://localhost:8000/metrics
```

## ğŸ“ Project Structure

```
Distributed-Video-Streaming-Simulator/
â”œâ”€â”€ app/                      # Next.js application
â”‚   â”œâ”€â”€ layout.tsx           # Root layout with metadata
â”‚   â”œâ”€â”€ page.tsx             # Main dashboard page
â”‚   â””â”€â”€ globals.css          # Global styles
â”œâ”€â”€ components/              # React components
â”‚   â”œâ”€â”€ ui/                  # Reusable UI components (shadcn/ui)
â”‚   â”‚   â”œâ”€â”€ card.tsx
â”‚   â”‚   â”œâ”€â”€ sidebar.tsx
â”‚   â”‚   â”œâ”€â”€ toast.tsx
â”‚   â”‚   â””â”€â”€ empty.tsx
â”‚   â”œâ”€â”€ sidebar.tsx          # Navigation sidebar
â”‚   â”œâ”€â”€ header.tsx           # Dashboard header
â”‚   â”œâ”€â”€ metrics-grid.tsx     # Metrics display grid
â”‚   â””â”€â”€ quality-distribution.tsx  # Quality charts
â”œâ”€â”€ server/                  # Python gRPC server
â”‚   â”œâ”€â”€ video_server.py      # Main server implementation
â”‚   â”œâ”€â”€ video_streaming.proto # gRPC service definition
â”‚   â””â”€â”€ Dockerfile           # Server container image
â”œâ”€â”€ client/                  # Load simulator
â”‚   â”œâ”€â”€ load_simulator.py    # Client implementation
â”‚   â””â”€â”€ Dockerfile           # Client container image
â”œâ”€â”€ kubernetes/              # Kubernetes manifests
â”‚   â”œâ”€â”€ video-server-deployment.yaml
â”‚   â”œâ”€â”€ client-deployment.yaml
â”‚   â”œâ”€â”€ prometheus-config.yaml
â”‚   â””â”€â”€ grafana-deployment.yaml
â”œâ”€â”€ grafana/                 # Grafana dashboards
â”‚   â””â”€â”€ dashboard.json       # Pre-configured dashboard
â”œâ”€â”€ scripts/                 # Deployment scripts
â”‚   â””â”€â”€ build-and-deploy.sh  # Build and deploy automation
â”œâ”€â”€ lib/                     # Utility libraries
â”œâ”€â”€ hooks/                   # React hooks
â”œâ”€â”€ styles/                  # Additional styles
â”œâ”€â”€ public/                  # Static assets
â”œâ”€â”€ package.json             # Node.js dependencies
â”œâ”€â”€ tsconfig.json            # TypeScript configuration
â”œâ”€â”€ next.config.mjs          # Next.js configuration
â”œâ”€â”€ tailwind.config.ts       # Tailwind CSS configuration
â””â”€â”€ README.md               # This file
```

## ğŸ“¡ gRPC API Documentation

### Service Definition

The video streaming service is defined in `server/video_streaming.proto`:

```protobuf
service VideoStreamingService {
  // Stream video chunks to client
  rpc StreamVideoChunks(StreamRequest) returns (stream VideoChunk);
  
  // Get server health status
  rpc GetServerHealth(HealthRequest) returns (HealthResponse);
}
```

### Streaming Video

**Request:**
```protobuf
message StreamRequest {
  string video_id = 1;      // ID of the video to stream
  string quality = 2;       // "low", "medium", or "high"
  string client_id = 3;     // Client identifier
}
```

**Response (Stream):**
```protobuf
message VideoChunk {
  bytes data = 1;           // Chunk binary data
  int32 chunk_number = 2;   // Chunk sequence number
  int64 timestamp = 3;      // Unix timestamp (ms)
  int32 size_bytes = 4;     // Chunk size in bytes
  string quality = 5;       // Quality level
}
```

### Quality Levels

| Quality | Chunk Size | Bitrate (approx) |
|---------|-----------|------------------|
| Low     | 256 KB    | ~4 Mbps          |
| Medium  | 512 KB    | ~8 Mbps          |
| High    | 1 MB      | ~16 Mbps         |

### Streaming Characteristics
- **Chunks per second**: 20
- **Total chunks per video**: 1200 (1-minute video)
- **Network delay**: 50-100ms per chunk (simulated)
- **Error rate**: 1% (simulated for testing)

## âš™ï¸ Configuration

### Environment Variables

#### Server Configuration
```bash
NODE_ID=node-1              # Server node identifier
GRPC_PORT=50051            # gRPC server port
```

#### Client Configuration
```bash
SERVER_ADDRESSES=localhost:50051,localhost:50052  # Comma-separated server list
NUM_CLIENTS=100            # Number of concurrent clients
```

### Kubernetes Resource Limits

```yaml
resources:
  requests:
    memory: "256Mi"
    cpu: "250m"
  limits:
    memory: "512Mi"
    cpu: "500m"
```

### Scaling

To scale the video servers:
```bash
kubectl scale deployment video-server --replicas=10
```

## ğŸ”§ Development

### Running Tests

```bash
# Frontend tests
pnpm test

# Lint code
pnpm lint
```

### Code Generation

When modifying the proto file:

```bash
# Server
cd server
python -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. video_streaming.proto

# Client
cd client
python -m grpc_tools.protoc -I../server --python_out=. --grpc_python_out=. ../server/video_streaming.proto
```

### Debugging

```bash
# View server logs
kubectl logs -l app=video-server -f

# View client logs
kubectl logs -l app=video-client -f

# Port forward for local debugging
kubectl port-forward service/video-server-service 50051:50051
```

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

Please ensure your code follows the existing style and includes appropriate tests.

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Built with [Next.js](https://nextjs.org/)
- UI components from [shadcn/ui](https://ui.shadcn.com/)
- Icons from [Lucide](https://lucide.dev/)
- Monitoring powered by [Prometheus](https://prometheus.io/) and [Grafana](https://grafana.com/)

## ğŸ“§ Contact

For questions or support, please open an issue on GitHub.

---

**Note**: This is a simulation project for educational and demonstration purposes. It simulates video streaming behavior and is not intended for production video delivery.
